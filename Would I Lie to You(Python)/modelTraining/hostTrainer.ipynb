{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `This file trains the model on host-only dataset. Remember to include the dataset file (in npy) in the current folder and change parameters if needed before running the file.`\n",
    "\n",
    "Last updated on August 4th, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#for plotting\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6701</th>\n",
       "      <th>6702</th>\n",
       "      <th>6703</th>\n",
       "      <th>6704</th>\n",
       "      <th>6705</th>\n",
       "      <th>6706</th>\n",
       "      <th>6707</th>\n",
       "      <th>6708</th>\n",
       "      <th>6709</th>\n",
       "      <th>6710</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01e01-1</td>\n",
       "      <td>lee</td>\n",
       "      <td>0</td>\n",
       "      <td>3.3000023105998935</td>\n",
       "      <td>71.86671698639998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21895666420459747</td>\n",
       "      <td>0.17740166187286377</td>\n",
       "      <td>-0.09458483010530472</td>\n",
       "      <td>-0.024067997932434082</td>\n",
       "      <td>0.14948584139347076</td>\n",
       "      <td>-0.19993917644023895</td>\n",
       "      <td>0.18439863622188568</td>\n",
       "      <td>0.31499582529067993</td>\n",
       "      <td>-0.1232866644859314</td>\n",
       "      <td>-0.39259663224220276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01e01-2</td>\n",
       "      <td>david</td>\n",
       "      <td>1</td>\n",
       "      <td>7.944450006999887</td>\n",
       "      <td>68.07782544459997</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06908415257930756</td>\n",
       "      <td>0.0735771581530571</td>\n",
       "      <td>0.021056152880191803</td>\n",
       "      <td>0.21295836567878723</td>\n",
       "      <td>0.1802792251110077</td>\n",
       "      <td>-0.11115138232707977</td>\n",
       "      <td>0.12789243459701538</td>\n",
       "      <td>0.22979138791561127</td>\n",
       "      <td>-0.03769122064113617</td>\n",
       "      <td>-0.17092905938625336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s01e01-3</td>\n",
       "      <td>david</td>\n",
       "      <td>0</td>\n",
       "      <td>4.44444755630002</td>\n",
       "      <td>48.51114507770012</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14053265750408173</td>\n",
       "      <td>0.24185998737812042</td>\n",
       "      <td>0.07830483466386795</td>\n",
       "      <td>0.21046167612075806</td>\n",
       "      <td>0.051085006445646286</td>\n",
       "      <td>0.14389000833034515</td>\n",
       "      <td>0.24220730364322662</td>\n",
       "      <td>0.3750411570072174</td>\n",
       "      <td>0.30338799953460693</td>\n",
       "      <td>-0.22965334355831146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s01e01-4</td>\n",
       "      <td>lee</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500011876200006</td>\n",
       "      <td>67.14458943080012</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2103462517261505</td>\n",
       "      <td>0.18148276209831238</td>\n",
       "      <td>0.05595875531435013</td>\n",
       "      <td>-0.009519249200820923</td>\n",
       "      <td>0.20049774646759033</td>\n",
       "      <td>0.1327437460422516</td>\n",
       "      <td>0.4750293493270874</td>\n",
       "      <td>0.24504275619983673</td>\n",
       "      <td>0.3577592670917511</td>\n",
       "      <td>-0.2574981451034546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s01e01-5</td>\n",
       "      <td>david</td>\n",
       "      <td>1</td>\n",
       "      <td>4.922214076599971</td>\n",
       "      <td>137.44421699170002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023250998929142952</td>\n",
       "      <td>0.2042246013879776</td>\n",
       "      <td>0.1943531334400177</td>\n",
       "      <td>0.0881553590297699</td>\n",
       "      <td>0.16788558661937714</td>\n",
       "      <td>-0.23709188401699066</td>\n",
       "      <td>0.2678818702697754</td>\n",
       "      <td>0.23755134642124176</td>\n",
       "      <td>-0.02307339943945408</td>\n",
       "      <td>-0.2727155089378357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1    2                   3                   4    5    6     \\\n",
       "0  s01e01-1    lee    0  3.3000023105998935   71.86671698639998    1    1   \n",
       "1  s01e01-2  david    1   7.944450006999887   68.07782544459997    1    3   \n",
       "2  s01e01-3  david    0    4.44444755630002   48.51114507770012    1    2   \n",
       "3  s01e01-4    lee    0   5.500011876200006   67.14458943080012    1    4   \n",
       "4  s01e01-5  david    1   4.922214076599971  137.44421699170002    1    2   \n",
       "\n",
       "  7    8    9     ...                  6701                 6702  \\\n",
       "0    0    0    0  ...   0.21895666420459747  0.17740166187286377   \n",
       "1    1    2    0  ...   0.06908415257930756   0.0735771581530571   \n",
       "2    0    0    0  ...   0.14053265750408173  0.24185998737812042   \n",
       "3    0    0    0  ...    0.2103462517261505  0.18148276209831238   \n",
       "4    0    0    0  ...  0.023250998929142952   0.2042246013879776   \n",
       "\n",
       "                   6703                   6704                  6705  \\\n",
       "0  -0.09458483010530472  -0.024067997932434082   0.14948584139347076   \n",
       "1  0.021056152880191803    0.21295836567878723    0.1802792251110077   \n",
       "2   0.07830483466386795    0.21046167612075806  0.051085006445646286   \n",
       "3   0.05595875531435013  -0.009519249200820923   0.20049774646759033   \n",
       "4    0.1943531334400177     0.0881553590297699   0.16788558661937714   \n",
       "\n",
       "                   6706                 6707                 6708  \\\n",
       "0  -0.19993917644023895  0.18439863622188568  0.31499582529067993   \n",
       "1  -0.11115138232707977  0.12789243459701538  0.22979138791561127   \n",
       "2   0.14389000833034515  0.24220730364322662   0.3750411570072174   \n",
       "3    0.1327437460422516   0.4750293493270874  0.24504275619983673   \n",
       "4  -0.23709188401699066   0.2678818702697754  0.23755134642124176   \n",
       "\n",
       "                   6709                  6710  \n",
       "0   -0.1232866644859314  -0.39259663224220276  \n",
       "1  -0.03769122064113617  -0.17092905938625336  \n",
       "2   0.30338799953460693  -0.22965334355831146  \n",
       "3    0.3577592670917511   -0.2574981451034546  \n",
       "4  -0.02307339943945408   -0.2727155089378357  \n",
       "\n",
       "[5 rows x 6711 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data\n",
    "#dataset.form = [id, speaker, label, some features, opensmile, ngram, embedding]\n",
    "dataset = np.load(\"hostOnly.npy\", allow_pickle = True)\n",
    "dataset = np.delete(dataset, 3889, axis=1)\n",
    "dataset = np.delete(dataset, 3894, axis=1)\n",
    "\n",
    "#save the data into a csv file under the same directory\n",
    "df = pd.DataFrame(dataset)\n",
    "# df = df[df[1]==\"david\"]\n",
    "# df.to_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(predict_y, real_y, ifNpArr=False):\n",
    "    '''\n",
    "    parameters:\n",
    "    predict_y: npArr. the prediction array\n",
    "    real_y: npArr. the actual label\n",
    "    ifNpArr: the type of the output. If true, return a numpy array.\n",
    "\n",
    "    return:\n",
    "    npArr. or dict: the list or dictionary that stores the resulting data\n",
    "\n",
    "    reference: https://mmuratarat.github.io/2019-10-01/how-to-compute-AUC-plot-ROC-by-hand\n",
    "    '''\n",
    "    #lie detection\n",
    "    #lie is the positive class, truth is negative class\n",
    "    assert predict_y.shape ==real_y.shape\n",
    "    tp=0; tn=0; fp=0; fn=0\n",
    "    for i in range(len(predict_y)):\n",
    "        #the model predicts it is a lie/positive\n",
    "        if predict_y[i] == 0:\n",
    "            if real_y[i] == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1 \n",
    "        #the model predicts it is a truth/negative\n",
    "        else:\n",
    "            if real_y[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    accuracy = 1-np.count_nonzero(real_y-predict_y)/predict_y.shape[0]\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    specificity = fp/(fp+tn)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(real_y, predict_y)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    if ifNpArr:\n",
    "        return np.array([accuracy, precision, recall, specificity, f1, auc])\n",
    "    else:\n",
    "        return {\"accuracy\":\"%.3f\" % accuracy, \"precision\":\"%.3f\" % precision, \"recall\":\"%.3f\" % recall, \"specificity\":\"%.3f\" % specificity, \"f1\":\"%.3f\" % f1, \"auc\":\"%.3f\" % auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_individual_speaker(dataframe, speakerName, modelType, n=10, ifPCA=False, pcaNum=50):\n",
    "    '''\n",
    "    parameter:\n",
    "    dataframe: pandasDf. dataset\n",
    "    speakerName: str. the name of the host. Choose from \"angus\", \"david\", \"lee\", \"rob\"\n",
    "    modelType: str. the name of the machine learning model\n",
    "    n: the number of times to run before calculating percentiles\n",
    "    ifPCA: bool. if to conduct dimensionality reduction. default false\n",
    "    pcaNum: int. only effective when ifPCA is True. indicate the number of principal components to keep\n",
    "    '''\n",
    "\n",
    "    #choose a model\n",
    "    if modelType == \"LR\":\n",
    "        model = LogisticRegression()\n",
    "    elif modelType == \"RF\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif modelType == \"DT\":\n",
    "        model = DecisionTreeClassifier()\n",
    "    elif modelType == \"NB\":\n",
    "        model = GaussianNB()\n",
    "    elif modelType == \"MLP\":\n",
    "        model = MLPClassifier(hidden_layer_sizes=(1095, 1095, 1095, 1095, 1095, 1095),solver=\"sgd\",learning_rate_init=0.00134)\n",
    "    elif modelType == \"Ada\":\n",
    "        model = AdaBoostClassifier()\n",
    "    elif modelType == \"LSVM\":\n",
    "        model = LinearSVC()\n",
    "\n",
    "    #process the data\n",
    "    data = np.array(dataframe[dataframe[1]==speakerName])\n",
    "    data = data[:,2:].astype(float)\n",
    "\n",
    "    numTest = round(data.shape[0]*0.2)\n",
    "\n",
    "    #conduct dimensionality reduction\n",
    "    if ifPCA:\n",
    "        #norm the data\n",
    "        for i in range(1, data.shape[1]):\n",
    "            if np.std(data[:,i])==0:\n",
    "                continue\n",
    "            else:\n",
    "                data[:,i] = (data[:,i] - np.mean(data[:,i]))/np.std(data[:,i])\n",
    "\n",
    "        pcaModel = PCA(pcaNum)\n",
    "        pcaData = pcaModel.fit_transform(data[:,1:])\n",
    "        data = np.column_stack((data[:,0],pcaData))\n",
    "\n",
    "    statistics = []\n",
    "\n",
    "    for i in range(n):\n",
    "        #split the data\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "        test_y = data[:numTest,0]\n",
    "        test_x = data[:numTest,1:]\n",
    "        train_y = data[numTest:,0]\n",
    "        train_x = data[numTest:,1:]\n",
    "        print(test_y)\n",
    "        #train models\n",
    "        model.fit(train_x, train_y)\n",
    "        predict_y = model.predict(test_x)\n",
    "        print(predict_y, test_y)\n",
    "        statistics.append(get_statistics(predict_y, test_y, True))\n",
    "    \n",
    "    #make the pandas dataframe\n",
    "    df = pd.DataFrame(statistics, columns=[\"accuracy\", \"precision\", \"recall\", \"specificity\", \"f1\", \"auc\"])\n",
    "    return df.quantile([0.25, 0.5, 0.75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] [1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  precision  recall  specificity        f1       auc\n",
       "0.25  0.571429        0.5    0.25     0.083333  0.250000  0.571429\n",
       "0.50  0.714286        0.5    0.50     0.100000  0.333333  0.575000\n",
       "0.75  0.714286        0.5    0.50     0.200000  0.500000  0.650000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_for_individual_speaker(df, \"lee\", \"LR\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc7cae5cfb96b709b6e20795c35d6ed525a7bf528d24a73a8fe31e90ef10ad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
